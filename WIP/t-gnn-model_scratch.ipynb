{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4de96943",
   "metadata": {},
   "source": [
    "# Temporal GNN Model: Scratch\n",
    "Overall purpose here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f80b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge93qew/PycharmProjects/Forschungspraxis/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "from torch_geometric.utils import is_undirected "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde4068",
   "metadata": {},
   "source": [
    "### 1. Load the Temporal Graph Dataset\n",
    "Before defining the GNN model we load the dataset that we created in a previous tutorial and split it according to a predefined ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ccfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_dataset = torch.load('../tg_dataset.pt')\n",
    "for i in tg_dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ec0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = temporal_signal_split(tg_dataset, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb546b4",
   "metadata": {},
   "source": [
    "### 2. Define the GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb052be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "from torch_geometric.nn.conv import GATv2Conv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcee3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.01\n",
    "optimizer = 'adam'\n",
    "n_heads_sal = 4\n",
    "n_heads_tal = 16\n",
    "mini_batch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self,node_features):\n",
    "        super(RecurrentGCN,self).__init__()\n",
    "        self.recurrent = DCRNN(node_features,992,1)\n",
    "        self.linear = torch.nn.Linear(992,1)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6167d01",
   "metadata": {},
   "source": [
    "### 2. Define Custom Temporal Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da2e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter, Sigmoid\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    '''\n",
    "    copied from: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html\n",
    "    '''\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q,k.transpose(-2,-1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3630c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_window():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c137735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13182efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttentionLayer(torch.nn.Module):\n",
    "    '''\n",
    "    Needs: window_size\n",
    "    How to handle batches of data?\n",
    "    Implementation inspired by DySAT's Temporal Attention Layer\n",
    "    https://github.com/aravindsankar28/DySAT/blob/master/models/DySAT/layers.py\n",
    "    '''\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int, # num features i.e. 2048 without SAL\n",
    "        out_channels: int,\n",
    "        n_heads: int = 1,\n",
    "        window_size = 3,\n",
    "        positional_enc = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(TemporalAttnLayer,self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_heads = n_heads\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        # projection matrix init xavier\n",
    "        # define the matrices as Parameters Parameter(torch.Tensor(....))\n",
    "        # matmuls + multi-head (concat?)\n",
    "        \n",
    "        # mask M?\n",
    "        \n",
    "        # softmax\n",
    "        # final multiplication\n",
    "        \n",
    "        if positional_enc:\n",
    "            self.pos_enc = torch.nn.Parameter(torch.randn(n_heads,in_channels,window_size))\n",
    "        \n",
    "        \n",
    "        self.W_Q = torch.nn.Parameter()\n",
    "        \n",
    "        def forward(self, h, edge_index, edge_attr):\n",
    "            #self.att = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "            for i in range(n_heads):\n",
    "                PE_head_i = self.pos_enc[i]\n",
    "                x_i = h + PE_head_i # 500x3\n",
    "                X = x_i.T # transpose to get shape 3x500\n",
    "                \n",
    "\n",
    "                X = ...\n",
    "\n",
    "\n",
    "\n",
    "        #self.reset_parameters()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dca83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = torch.nn.Parameter(torch.randn(16,500,3)) # n_heads,in_channels,window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92041a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8fe478",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q[2].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f7d81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4],\n",
       "       [9, 9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([[1,2],[0,0]]) + np.array([[1,2],[9,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.nn import MultiheadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1adf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyGLIP(torch.nn.Module):\n",
    "    def __init__(self,in_feat_size):\n",
    "        super(DyGLIP,self).__init__()\n",
    "        # create full edge list for bi-directional message passing. so far only unidirectional\n",
    "        # Spatial Attention Layers\n",
    "        self.sal1 = GATv2Conv(in_feat_size,out_channels=128,heads=4,edge_dim=1) # wegen multi head: *4\n",
    "        self.sal2 = GATv2Conv(in_channels=128*4,out_channels=128,heads=4,edge_dim=1)\n",
    "        \n",
    "        # Temporal Attention Layers TBD\n",
    "        #self.attention_tal = 1  # temporal attention\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # 1. Add positional encoding to x: row-wise one-hot vector\n",
    "        # x = x & one-hot\n",
    "        h1 = self.sal1(x,edge_index,edge_attr)\n",
    "        h2 = self.sal2(h1,edge_index,edge_attr)\n",
    "        # Use list to keep track of the historic structural GAT features to use that as \n",
    "        # input for the temporal GAT\n",
    "        \n",
    "        return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270cd357",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DyGLIP(in_feat_size=2048)  # should be set to 2048\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15095f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017d515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe60da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eccc8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],\n",
       "       [ 9., 10., 11., 12., 13., 14., 15., 16.],\n",
       "       [17., 18., 19., 20., 21., 22., 23., 24.],\n",
       "       [25., 26., 27., 28., 29., 30., 31., 32.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "f1 = range(1,9)\n",
    "f2 = range(9,17)\n",
    "f3 = range(17,25)\n",
    "f4 = range(25,33)\n",
    "A = np.array([f1,f2,f3,f4]) / 1# 4 nodes with 8 features\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(A,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d2b764e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 204.        ,  513.3887416 ,  833.31626649, 1155.05844008],\n",
       "       [ 513.3887416 , 1292.        , 2097.13328141, 2906.83332856],\n",
       "       [ 833.31626649, 2097.13328141, 3404.        , 4718.27934739],\n",
       "       [1155.05844008, 2906.83332856, 4718.27934739, 6540.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outer product\n",
    "scaling = np.outer(norm(A,axis=1), norm(A,axis=1))\n",
    "scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4927c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [1, 3, 3, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = np.array([[0,1,2,3],[1,3,3,0]])\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c505d48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 0, 1, 1, 2, 3, 3, 3],\n",
      "        [1, 3, 0, 3, 3, 0, 1, 2]]), tensor([5000., 8000., 5000., 6000., 7000., 8000., 6000., 7000.]))\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj,to_undirected\n",
    "E = torch.tensor(E)\n",
    "#K = to_dense_adj(E).clone().detach().numpy()\n",
    "#K = np.reshape(K, (4,4))\n",
    "#K\n",
    "print(to_undirected(E,edge_attr=torch.Tensor([5000,6000,7000,8000]))) # label list\n",
    "E,L = to_undirected(E,edge_attr=torch.Tensor([5000,6000,7000,8000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8206e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "COS = A@A.T\n",
    "COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf70c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "klklk = COS / scaling\n",
    "klklk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa95070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = E.T\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18ca5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Edge between node 0 and node 0 has similarity value:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'COS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(E)): \n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Edge between node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mE[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mE[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has similarity value:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mCOS\u001b[49m[E[i][\u001b[38;5;241m0\u001b[39m],E[i][\u001b[38;5;241m1\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'COS' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(E)): \n",
    "    print(f'{i}. Edge between node {E[i][0]} and node {E[i][1]} has similarity value:')\n",
    "    print(COS[E[i][0],E[i][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29a31d",
   "metadata": {},
   "source": [
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cde2841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],\n",
       "       [ 9., 10., 11., 12., 13., 14., 15., 16.],\n",
       "       [17., 18., 19., 20., 21., 22., 23., 24.],\n",
       "       [25., 26., 27., 28., 29., 30., 31., 32.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a75643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12., 13., 14., 15., 16.],\n",
       "        [17., 18., 19., 20., 21., 22., 23., 24.],\n",
       "        [25., 26., 27., 28., 29., 30., 31., 32.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_tensor = torch.tensor(A)\n",
    "tmp_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d87c6bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12., 13., 14., 15., 16.],\n",
       "        [17., 18., 19., 20., 21., 22., 23., 24.],\n",
       "        [25., 26., 27., 28., 29., 30., 31., 32.]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_tensor.requires_grad = True\n",
    "tmp_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ca386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c01d065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12., 13., 14., 15., 16.],\n",
       "        [17., 18., 19., 20., 21., 22., 23., 24.],\n",
       "        [25., 26., 27., 28., 29., 30., 31., 32.]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor(A, requires_grad=True)\n",
    "#tensor = torch.tensor(A)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "477d7338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14.2829, 35.9444, 58.3438, 80.8703], dtype=torch.float64,\n",
       "       grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_row = torch.linalg.norm(tensor,dim=1)\n",
    "norm_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4669453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 204.0000,  513.3887,  833.3163, 1155.0584],\n",
       "        [ 513.3887, 1292.0000, 2097.1333, 2906.8333],\n",
       "        [ 833.3163, 2097.1333, 3404.0000, 4718.2793],\n",
       "        [1155.0584, 2906.8333, 4718.2793, 6540.0000]], dtype=torch.float64,\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.outer(norm_row,norm_row)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e181bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominator = tensor @ tensor.T\n",
    "nominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(tensor,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5b6bca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 204.,  492.,  780., 1068.],\n",
       "        [ 492., 1292., 2092., 2892.],\n",
       "        [ 780., 2092., 3404., 4716.],\n",
       "        [1068., 2892., 4716., 6540.]], dtype=torch.float64,\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take this.\n",
    "nom = torch.matmul(tensor,torch.transpose(tensor,0,1))\n",
    "nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_distance = nominator / alpha\n",
    "cos_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d10a86f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9583, 0.9360, 0.9246],\n",
       "        [0.9583, 1.0000, 0.9976, 0.9949],\n",
       "        [0.9360, 0.9976, 1.0000, 0.9995],\n",
       "        [0.9246, 0.9949, 0.9995, 1.0000]], dtype=torch.float64,\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_distance = nom / alpha\n",
    "cosine_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3b8525b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.7228, 0.7183, 0.7160],\n",
       "        [0.7228, 0.7311, 0.7306, 0.7301],\n",
       "        [0.7183, 0.7306, 0.7311, 0.7310],\n",
       "        [0.7160, 0.7301, 0.7310, 0.7311]], dtype=torch.float64,\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig = Sigmoid()\n",
    "scores = sig(cosine_distance)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones(scores.size())\n",
    "zeros = torch.zeros(scores.size())\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(scores >0.5,scores,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa7a1737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.7228, 0.5001, 0.7160],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000],\n",
       "        [0.7183, 0.7306, 0.7311, 0.7310],\n",
       "        [0.7160, 0.7301, 0.7310, 0.7311]], dtype=torch.float64,\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0:2][1] = 0.1\n",
    "scores[0][2] = 0.500100000000000001\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores  = torch.round(scores.clone())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3412b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1, 2, 3, 3, 3],\n",
       "        [1, 3, 0, 3, 3, 0, 1, 2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edbf79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = E.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ec7396f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Edge between node 0 and node 1 has similarity value:\n",
      "1. Edge between node 0 and node 3 has similarity value:\n",
      "2. Edge between node 1 and node 0 has similarity value:\n",
      "3. Edge between node 1 and node 3 has similarity value:\n",
      "4. Edge between node 2 and node 3 has similarity value:\n",
      "5. Edge between node 3 and node 0 has similarity value:\n",
      "6. Edge between node 3 and node 1 has similarity value:\n",
      "7. Edge between node 3 and node 2 has similarity value:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.7228, 0.7160, 0.1000, 0.1000, 0.7310, 0.7160, 0.7301, 0.7310],\n",
       "       dtype=torch.float64, grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lisst = []\n",
    "for i in range(len(E)): \n",
    "    print(f'{i}. Edge between node {E[i][0]} and node {E[i][1]} has similarity value:')\n",
    "    #print(scores[E[i][0],E[i][1]])\n",
    "    lisst.append(scores[E[i][0],E[i][1]])\n",
    "    #print(lisst)\n",
    "labells = torch.stack(lisst, dim=0)\n",
    "labells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1be637",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([torch.tensor(1.0),torch.tensor(2.0),torch.tensor(3.0)],requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ababfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([x, x, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "lisst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "neki = []\n",
    "for i in range(4):\n",
    "    neki.append(torch.tensor(float(i),requires_grad=True))\n",
    "torch.stack(neki, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0764da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neki[0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098bab1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae4ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26882af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.where(scores >0.5,scores,scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35549bf6",
   "metadata": {},
   "source": [
    ">>> torch.masked_select(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5607998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.7228, 0.5001, 0.7160],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000],\n",
       "        [0.7183, 0.7306, 0.7311, 0.7310],\n",
       "        [0.7160, 0.7301, 0.7310, 0.7311]], dtype=torch.float64,\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2e2ad91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [0, 3],\n",
       "        [1, 0],\n",
       "        [1, 3],\n",
       "        [2, 3],\n",
       "        [3, 0],\n",
       "        [3, 1],\n",
       "        [3, 2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7f856f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False,  True, False,  True],\n",
       "         [ True, False, False,  True],\n",
       "         [False, False, False,  True],\n",
       "         [ True,  True,  True, False]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = to_dense_adj(E.T).type(torch.bool)\n",
    "mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c97d847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7228, 0.7160, 0.1000, 0.1000, 0.7310, 0.7160, 0.7301, 0.7310],\n",
       "       dtype=torch.float64, grad_fn=<MaskedSelectBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(scores, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a832e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa67b773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb26680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43775cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db538755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732ea7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c718e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7933b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_dist_edge_embeddings(features,edge_list):\n",
    "    norm_row = norm(features,axis=1)\n",
    "    scaling = np.outer(norm_row,norm_row)\n",
    "    cos_dist = (features@features.T) / scaling\n",
    "    # Sigmoid\n",
    "    sig = Sigmoid()\n",
    "    scores = sig(torch.Tensor(cos_dist))\n",
    "    E = edge_list.T\n",
    "    \n",
    "    print(scores)\n",
    "    scores[3][2] = 0.4444\n",
    "    print(scores)\n",
    "    scores[scores>0.5] = 1\n",
    "    print(scores)\n",
    "    scores[scores<=0.5] = 0\n",
    "    print(scores)\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(E)): \n",
    "        print(f'{i}. Edge between node {E[i][0]} and node {E[i][1]} has score value:')\n",
    "        print(scores[E[i][0],E[i][1]])\n",
    "        #labels.append(int(scores[E[i][0],E[i][1]].numpy()))\n",
    "        labels.append(scores[E[i][0],E[i][1]])\n",
    "    labels = torch.Tensor(labels)\n",
    "    print(f'Score matrix: \\n{scores}\\n')\n",
    "    #print(f'Predictions: \\n{preds}\\n')\n",
    "    print(f'Labels: {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d5bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dist_edge_embeddings(A,E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a2bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc301c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        if time > 0:\n",
    "            # updated edge list to undirected \n",
    "            # directed edge_list: snapshot.edge_index used for calculating the cosine distance \n",
    "            # and loss (explot symmetry)\n",
    "            # for normal message passing we need the undirected graph, i.e. the edge list with 2* elements\n",
    "            print(time)\n",
    "            print(snapshot.edge_index)\n",
    "            #y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "            pred = model(snapshot.x,snapshot.edge_index,snapshot.edge_attr)\n",
    "            print(snapshot.edge_index.shape)\n",
    "            print(snapshot.x.shape)\n",
    "            print(pred.shape)\n",
    "        #cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "        #cost = cost/(time+1)\n",
    "        #cost.backward()\n",
    "        #optimizer.step()\n",
    "        #optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a73c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8187bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90cfb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a0bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca427b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
