{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd040655",
   "metadata": {},
   "source": [
    "# Bounding Box Extraction\n",
    "In this notebook we extract the bounding boxes (BBs) from the [WILDTRACK](https://openaccess.thecvf.com/content_cvpr_2018/papers/Chavdarova_WILDTRACK_A_Multi-Camera_CVPR_2018_paper.pdf) images using the coordinates provided in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d9c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba19da",
   "metadata": {},
   "source": [
    "#### 1. Creating Folders for Cropped BBs\n",
    "In each camera directory create a new folder `croppedBB` in which we are going to store the cropped BBs. Execute the following code snippet only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ef160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = ['C1','C2','C3','C4','C5','C6','C7']\n",
    "\n",
    "parent_dir = '/home/ge93qew/WILDTRACK/Image_subsets/'\n",
    "child_dir = 'croppedBB/'\n",
    "\n",
    "for cam in cameras:\n",
    "    path = os.path.join(parent_dir,cam,child_dir)\n",
    "    isExist = os.path.exists(path)\n",
    "\n",
    "    if not isExist:    \n",
    "        os.makedirs(path)\n",
    "        print(f\"The new directory {path} is created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbf051",
   "metadata": {},
   "source": [
    "#### 2. Loading and Cropping the Images\n",
    "Once the target folder has been created, we can crop the BBs. A cropped box represents one person and is associated with a `person_id`, `frame_id` and the corresponding box coordinates. We have 7 cameras with overlapping field of view each providing 400 frames. All the information and data are given in the WILDTRACK dataset. \n",
    "\n",
    "I made the following observations and adapted my code accordingly:\n",
    "- There are cases where the ground truth BB of a person exceeds the image boundary, i.e. the BB cannot capture the person on the specific image. This is most probably because the BBs have been determined by projection using all 7 camera perspectives. My remedy was to just omit these samples and to log them in `broken_samples_log`.\n",
    "- Surprisingly, there are images that obviously show more than 10 pedestrians that haven't been annotated, i.e. there are persons in some images for whom there are no BBs.\n",
    "- Keep in mind that one cropped box may show more than 1 person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d6baca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/ge93qew/WILDTRACK/Image_subsets/C1/gt/gt.txt,\n",
      "im_path: /home/ge93qew/WILDTRACK/Image_subsets/C1/img1/,\n",
      "st_path: /home/ge93qew/WILDTRACK/Image_subsets/C1/croppedBB/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:17<00:00, 22.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/ge93qew/WILDTRACK/Image_subsets/C2/gt/gt.txt,\n",
      "im_path: /home/ge93qew/WILDTRACK/Image_subsets/C2/img1/,\n",
      "st_path: /home/ge93qew/WILDTRACK/Image_subsets/C2/croppedBB/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:16<00:00, 24.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/ge93qew/WILDTRACK/Image_subsets/C3/gt/gt.txt,\n",
      "im_path: /home/ge93qew/WILDTRACK/Image_subsets/C3/img1/,\n",
      "st_path: /home/ge93qew/WILDTRACK/Image_subsets/C3/croppedBB/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:16<00:00, 24.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/ge93qew/WILDTRACK/Image_subsets/C4/gt/gt.txt,\n",
      "im_path: /home/ge93qew/WILDTRACK/Image_subsets/C4/img1/,\n",
      "st_path: /home/ge93qew/WILDTRACK/Image_subsets/C4/croppedBB/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:15<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/ge93qew/WILDTRACK/Image_subsets/C5/gt/gt.txt,\n",
      "im_path: /home/ge93qew/WILDTRACK/Image_subsets/C5/img1/,\n",
      "st_path: /home/ge93qew/WILDTRACK/Image_subsets/C5/croppedBB/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:15<00:00, 26.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/ge93qew/WILDTRACK/Image_subsets/C6/gt/gt.txt,\n",
      "im_path: /home/ge93qew/WILDTRACK/Image_subsets/C6/img1/,\n",
      "st_path: /home/ge93qew/WILDTRACK/Image_subsets/C6/croppedBB/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:16<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/ge93qew/WILDTRACK/Image_subsets/C7/gt/gt.txt,\n",
      "im_path: /home/ge93qew/WILDTRACK/Image_subsets/C7/img1/,\n",
      "st_path: /home/ge93qew/WILDTRACK/Image_subsets/C7/croppedBB/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:15<00:00, 26.18it/s]\n"
     ]
    }
   ],
   "source": [
    "cameras = ['C1','C2','C3','C4','C5','C6','C7']\n",
    "\n",
    "parent_dir = '/home/ge93qew/WILDTRACK/Image_subsets/'\n",
    "img_child_dir = 'img1/'\n",
    "gt_child_dir = 'gt/gt.txt'\n",
    "store_dir = 'croppedBB/'\n",
    "broken_samples_log = ['img_dir, frame_id, cam_id, person_id, xmin, ymin, xmax, ymax']\n",
    "\n",
    "for cam in cameras:\n",
    "    gt_path = os.path.join(parent_dir,cam,gt_child_dir)\n",
    "    img_path = os.path.join(parent_dir,cam,img_child_dir)\n",
    "    store_path = os.path.join(parent_dir,cam,store_dir)\n",
    "    print(f'gt_path: {gt_path},\\nim_path: {img_path},\\nst_path: {store_path}')\n",
    "    data = pd.read_csv(gt_path, sep=\",\", header=None)\n",
    "    data.columns = [\"frame_id\", \"person_id\", \"xmin\", \"ymin\",\"dx\",\"dy\",\"1.0\",\"none\",\"none\",\"none\"]   \n",
    "    \n",
    "    for i in tqdm(range(1,401)):\n",
    "        bounding_boxes = data.loc[data['frame_id'] == i]\n",
    "        \n",
    "        person_ids = bounding_boxes.person_id\n",
    "        frame_ids = bounding_boxes.frame_id\n",
    "        xmins = bounding_boxes.xmin\n",
    "        ymins = bounding_boxes.ymin\n",
    "        dxs = bounding_boxes.dx\n",
    "        dys = bounding_boxes.dy\n",
    "        \n",
    "        im_labels = sorted(os.listdir(img_path))\n",
    "        img_dir = os.path.join(img_path,im_labels[i-1])\n",
    "        img = cv2.imread(img_dir) # load colored images\n",
    "        #print(img_dir)\n",
    "        for bb in range(len(bounding_boxes)):\n",
    "            xmin = xmins.iloc[bb]\n",
    "            ymin = ymins.iloc[bb]\n",
    "            dx = dxs.iloc[bb]\n",
    "            dy = dys.iloc[bb]\n",
    "            \n",
    "            ## Labels\n",
    "            gt_person_id = '{:04}'.format(person_ids.iloc[bb])\n",
    "            gt_frame_id = '{:04}'.format(frame_ids.iloc[bb])\n",
    "            gt_xmin = '{:04}'.format(xmin)\n",
    "            gt_ymin = '{:04}'.format(ymin)\n",
    "            gt_xmax = '{:04}'.format(xmin+dx)\n",
    "            gt_ymax = '{:04}'.format(ymin+dy)\n",
    "            \n",
    "            if xmin in range(1920) and ymin in range(1080) and xmin+dx in range(1920) and ymin+dy in range(1080):\n",
    "                cropped_image = img[ymin:ymin+dy, xmin:xmin+dx]\n",
    "                #cv2.imwrite(f'{store_path}{gt_frame_id}-{cam}-{gt_person_id}-{im_labels[i-1]}', cropped_image)\n",
    "            else:                              \n",
    "                tmp_path = f'{img_dir},{gt_frame_id}-{cam}-{gt_person_id}-{gt_xmin}-{gt_ymin}-{gt_xmax}-{gt_ymax}'\n",
    "                broken_samples_log.append(tmp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e1bdf1",
   "metadata": {},
   "source": [
    "Save the log file for the broken samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b10979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ge93qew/WILDTRACK/Image_subsets/broken-samples-log.txt', 'w') as f:\n",
    "    for item in broken_samples_log:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
